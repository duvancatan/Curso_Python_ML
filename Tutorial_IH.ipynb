{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Helper Logo](https://s3.amazonaws.com/public-rafa/impala-helper-logo-t.png)\n",
    "\n",
    "# Introducción a Impala Helper\n",
    "\n",
    "**Impala Helper** Es una Librería que permite interactuar con Impala desde Python, para facilitar la calendarización y automatización de procesos que involucren Consultas SQL al Aljibe de datos.\n",
    "\n",
    "## Prerrequisitos\n",
    "\n",
    "*  PyODBC (Instalar con Artifactory)\n",
    "*  Pysftp (Instalar con Artifactory)\n",
    "*  paramiko (Instalar con Artifactory)\n",
    "\n",
    "*  Driver de ODBC de Impala (Descargar del [sitio de Cloudera](https://www.cloudera.com/downloads/connectors/impala/odbc/2-6-2.html))\n",
    "*  Pandas (Viene con Anaconda preinstalado)\n",
    "*  Certificado Digital Para conectarse a Impala (pedirlo a DiCAGI!)\n",
    "*  PyArrow\n",
    "* **Si ya tienes HewNoMore ya tienes algunos de los prerrequisitos**\n",
    "\n",
    "\n",
    "## Funcionalidades\n",
    "\n",
    "*  **getQueries**( _rutaArchivo , params_ ) : Trae la lista de queries de un archivo, si se envían parámetros los reemplaza al traer la lista de consultas.\n",
    "\n",
    "*  **executeFile**(_rutaArchivo , params_ ) : Ejecuta los queries de un archivo. Si le mandas parámetros lo reemplaza antes de ejecutarlos.\n",
    "\n",
    "*  **execute**(_query , params_ ) : Ejecuta un query en específico.  especifico para lanzar consultas sin devolución de resultados.\n",
    "\n",
    "*  **toCSV** ( _query , rutaDestino , params_) : Ejecuta un query y manda los resultados a CSV a la ruta que le mandes. Si le mandas parámetros lo reemplaza antes de ejecutarlo.\n",
    "\n",
    "*  **fromCSV**(_rutaArchivo , nombreTabla , serverOpts_) : Toma un archivo CSV , trata de estimar cuales son los tipos de datos y crea una tabla nueva en impala.  \n",
    "\n",
    "*  **fromPandasDF**(_dataFrame , nombreTabla , serverOpts_) : Toma un dataframe de Pandas , trata de estimar cuales son los tipos de datos y crea una tabla nueva en impala.  \n",
    "\n",
    "*  **getRows**( _query , params_ ) : Trae los resultados de un Query en una lista de python.  Lo ideal es que esta función solo se utilice para resultados limitados.  Por ejemplo no hacerlo para traerse 1 millón de registros.\n",
    "\n",
    "*  **getDataFrame**( _query , params_ ) : Trae los resultados de un Query a un DataFrame de Pandas.  Lo ideal es que esta función solo se utilice para resultados limitados.  Por ejemplo no hacerlo para traerse 1 millón de registros.\n",
    "\n",
    "*  **getDataFrame**( _query , params_ ) : Trae los resultados de un Query a un DataFrame de Pandas.  Lo ideal es que esta función solo se utilice para resultados limitados.  Por ejemplo no hacerlo para traerse 1 millón de registros.\n",
    "\n",
    "*  **tableSize**( _tabla , sizeFmt = \"B\"_ ):  Devuelve el tamaño (almacenamiento físico) de una tabla de impala.  Por defecto el valor esta en bytes.  Se puede establecer los siguientes formatos de tamaño: \"YB\",\"ZB\",\"EB\",\"PB\",\"TB\",\"GB\",\"MB\",\"KB\", \"B\".\n",
    "\n",
    "*  **muestraAleatoria**( _tabla , pct = 0.01_ ):  Genera una muestra aleatoria de una tabla , por defecto es una muestra del 1% de los datos.\n",
    "\n",
    "*  **muestraEstratificada**( _tabla , estratos , pct = 0.01_ ):  Genera una muestra aleatoria estratificada de una tabla , se envia tambien las columnas que combinan los estratos.  por defecto se tiene una muestra del 1%.\n",
    "\n",
    "*  **oneHot**( _table , colsOHE_) : Añade columnas por medio de _**One Hot Encoding (OHE)**_ a una tabla.  Recibe la tabla como parámetro y una lista de columnas a las cuales hacer OHE. La función hace un distinct de los valores de cada columna y genera una nueva columna por cada valor.  La función retorna un diccionario donde cada id (columna nueva) identifica a que valor corresponde.   \n",
    "\n",
    "*  **transpose**( _tabla , colsGroup , colsTrans , colsSum_) : Una semitransposición de una tabla, donde se definen columnas de agrupación, las columnas a transponer y que valor se debe poner en la suma de la transposición.\n",
    "\n",
    "*  **enmascarar**( _tabla , variables , saltI = None , saltT = None_) : Enmascaramiento de variables en una tabla (bajo función de Hash de 512 bits). Usa funciones propias de impala para generar variables enmascaradas. Puede utilizar sales enviadas o generadas automáticamente.\n",
    "\n",
    "*  **enmascararLong**( _tabla , variables , tabla_original = None_) : Enmascaramiento de variables en una tabla, tratando de evitar cambios en longitud de campos.  Usa 'tablas de verdad' con el valor original y el generado para cada campo.\n",
    "\n",
    "*  **estabVariables**( _tabla , groupCols , varbl = None , exclude = None_) : Esta funcionalidad permite hacer un análisis de la estabilidad de variables en términos de algún(os) campo(s) de la tabla y genera un análisis de la distribución de las variables.\n",
    "\n",
    "*  **useDataBase**( _nombreDB_ ) : Por si se quiere cambiar la base de datos por defecto en el camino.\n",
    "\n",
    "*  **close()**  :  Al finalizar el programa se debe cerrar la conexión.\n",
    "\n",
    "## Modo de Uso\n",
    "\n",
    "A continuación se describe paso a paso como utilizar la librería.  \n",
    "\n",
    "#### Acceso a GIT Analítico\n",
    "\n",
    "*  Debes tener un usuario en el Git Analítico.  Se puede crear Directamente sin pedir permiso [aqui](http://sbmdeqpc04/)!\n",
    "*  Pedir acceso al repositorio **Herramientas_Comunidad**.  Se puede solicitar a cualquier miembro de DiCAGI.\n",
    "*  Hacer un clone del repositorio en tu carpeta de git:\n",
    "> git clone http://sbmdeqpc04/rlarios/Herramientas_Comunidad.git\n",
    "*  Ya estas listo para comenzar a utilizar Impala Helper! (si tienes los prerrequisitos)\n",
    "\n",
    "A continuación se muestra el código de como usarlo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "# Se agrega la ruta donde quedó el Helper al path de direcciones de python\n",
    "sys.path.append( 'D:/git/Herramientas_Comunidad/aljibe_helper/'  )\n",
    "\n",
    "#Se agrega la librería\n",
    "from Impala_Helper import Helper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración\n",
    "\n",
    "Se debe definir un diccionario de Python con las siguientes variables:\n",
    "\n",
    "### Parámetros Obligatorios\n",
    "* **connStr**: Cadena de conexión a Impala.  Si tienes configurado el driver en tu equipo solo es necesario poner el nombre de como quedó configurado. por ejemplo, si en el administrador ODBC tienes una conexión configurada como impala-prod, la cadena de conexión sería **DSN=impala-prod**\n",
    "\n",
    "\n",
    "### Parámetros Opcionales\n",
    "* **db**:  (str) Base de Datos por defecto.  En general debe ser la base de datos de proceso del área.  Si no se envía por defecto es **default**.\n",
    "* **refresh**: (int) Indica el número de segundos que espera para refrescar la conexión.  El valor por defecto es **300** segundos, solo cambiar si se tienen procesos largos que pudieran beneficiarse por tener una conexión por mayor tiempo.  Recomendable **no** poner un valor de más de 10x60 segundos (10 minutos)\n",
    "* **infoLeng**:  (int) Limita el tamaño de los mensajes que muestra a una cantidad limitada.  Por defecto está en **50**.\n",
    "* **fetchSize**: (int) El tamaño de registros a traer por solicitud.  Esta en un valor por defecto de **10000**.  **Si no sabe como utilizarlo no cambie este parámetro**\n",
    "* **verbose**: (bool) Indica si imprime cada acción que ejecuta.  valor por defecto es **False**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {\n",
    "            \"connStr\" : \"DSN=Impala\" ,\n",
    "            \"db\" : \"proceso_cap_analit_y_gob_de_inf\" ,\n",
    "            \"verbose\" : True\n",
    "        }\n",
    "\n",
    "hp = Helper( cache )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar con Log\n",
    "\n",
    "En el caso que se desee inicializar el Helper y que automáticamente genere un archivo de log (para facilitar procesos de calendarización de procesos), se puede crear el logger (que está en la misma librería de impala helper) y se debe crear un objeto de log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Impala_Helper import Helper \n",
    "from logger import logger\n",
    "\n",
    "cache = { \"connStr\" : \"DSN=Impala\"  }\n",
    "\n",
    "log = logger( pathlog =\"/ruta/donde/almacenar/log/\" , logName = \"nombre_log.log\" )\n",
    "hp = Helper(cache , logger = log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# FUNCIONALIDADES\n",
    "\n",
    "\n",
    "# Ejecutar Un archivo sin parámetros\n",
    "\n",
    "La función recibe la ruta de un archivo .sql el cual ejecutará en el orden que se encuentren las consultas.  las consultas deberán estar separadas por punto y coma ( ; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaArchivo = 'D:/git/Herramientas_Comunidad/aljibe_helper/queries_ejemplo/sin_params.sql'\n",
    "\n",
    "hp.executeFile( rutaArchivo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar Un archivo con parámetros\n",
    "\n",
    "Uno puede ejecutar archivos con parámetros definidos en el archivo SQL.  Para definir un parámetro este debe estar dentro de llaves.  por ejemplo:\n",
    "\n",
    "> ... where year = {**anhoEjec**} \n",
    "\n",
    "Los parámetros que se envían a Helper son variables que se definen en un diccionario de python.  Estos pueden ser definidos fijos (como esta abajo) o crear una funcion que los calcule automaticamente, como la fecha de Hoy por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaArchivo2 = 'D:/git/Herramientas_Comunidad/aljibe_helper/queries_ejemplo/con_params.sql'\n",
    "\n",
    "import datetime\n",
    "\n",
    "# se calcula Hoy - 10 días\n",
    "hoy = datetime.date.today()\n",
    "mesA = (hoy - datetime.timedelta(10)).strftime('%Y%m%d')\n",
    "\n",
    "params = {\n",
    "    \"anhoFijo\" : 2018 ,\n",
    "    \"partition\" : datetime.date.today().strftime('%Y') ,\n",
    "    \"startDay\" : mesA \n",
    "}\n",
    "\n",
    "hp.executeFile( rutaArchivo2 , params )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traer Todos los queries de un archivo\n",
    "En algunos casos nos gustaría traer todas las consultas de un archivo.  Estos queries quedan en una lista de python.  Si a la función se le especifica un diccionario de parámetros como en el ejemplo anterior, la función reemplaza los parámetros en los queries antes de retornarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"partition\" : 2018 ,\n",
    "    \"startDay\" : 20181001\n",
    "}\n",
    "\n",
    "print(\"\\nQueries sin cambiar parámetros:\\n\")\n",
    "queries = hp.getQueries( rutaArchivo2  )\n",
    "print(queries)\n",
    "print( )\n",
    "\n",
    "print(\"\\nQueries cambiando parámetros:\\n\")\n",
    "queries = hp.getQueries( rutaArchivo2 , params )\n",
    "# Note que a los queries ya se le cambiaron los parámetros por las variables enviadas.\n",
    "print(queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traer una Consulta a CSV\n",
    "\n",
    "En ocasiones debemos traer resultados al equipo local en formato CSV.  Es posible traer una consulta e incluso usar parámetros en ella. (En este ejemplo no se envían parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaCSV = \"d:/Ejemplo_IH.csv\"\n",
    "query = \"select * from hp_debito_base limit 10\"\n",
    "\n",
    "hp.toCSV( query , rutaCSV ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enviar un archivo CSV a Tabla Impala\n",
    "\n",
    "En el caso de que queramos subir una tabla de parámetros a veces es necesario subir un archivo CSV como tabla impala.  Esta función internamente ejecuta un proceso de enviar el archivo al servidor y crear una **EXTERNAL TABLE** (el usuario debe tener permiso para crearla).\n",
    "\n",
    "Para esto la función requiere el parámetro de serverOpts, el cual puede ser de 2 tipos\n",
    "*  La ruta a un archivo json donde se encuentre los parámetros de user y password\n",
    "* un diccionario de python con los parámetros:\n",
    "> serverOpts = { \"user\" : \"tuUsuario\" , \"password\" : \"tuContraseña\" } \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaCSV = \"d:/Ejemplo_IH.csv\"\n",
    "tabla = \"tabla_parametros\"\n",
    "serverOpts = { \"user\" : \"tuUsuario\" , \"password\" : \"tuContraseña\" }\n",
    "\n",
    "hp.fromCSV( rutaCSV , tabla , serverOpts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enviar un dataframe de Pandas a Tabla Impala\n",
    "\n",
    "En el caso de que queramos subir una tabla de parámetros a veces es necesario subir un DataFrame de Pandas como tabla impala. Esta función internamente ejecuta un proceso de enviar el archivo al servidor y crear una **EXTERNAL TABLE** (el usuario debe tener permiso para crearla).\n",
    "\n",
    "Para esto la función requiere el parámetro de serverOpts, el cual puede ser de 2 tipos\n",
    "*  La ruta a un archivo json donde se encuentre los parámetros de user y password\n",
    "* un diccionario de python con los parámetros:\n",
    "> serverOpts = { \"user\" : \"tuUsuario\" , \"password\" : \"tuContraseña\" } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from hp_debito_base limit 5\"\n",
    "\n",
    "df = hp.getDataFrame(query)\n",
    "tabla = \"tabla_parametros_desde_df\"\n",
    "serverOpts = \"d:/archivoPass.json\"\n",
    "\n",
    "hp.fromPandasDF( df , tabla , serverOpts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traer los resultados a una lista de Python\n",
    "Trae un query a una lista de python y devuelve un header (nombres de columnas separadas por comas) y la lista de python.  También recibe parámetros en caso de ser necesario.\n",
    "\n",
    "La función retorna dos variables:\n",
    "*  El header que es un string con las columnas del query (separado por comas).\n",
    "*  Los resultados que es una lista de python, donde cada posición es una lista con cada registro (cada registr es una lista de campos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from hp_debito_base limit 100\"\n",
    "\n",
    "header , results = hp.getRows(query)\n",
    "\n",
    "print(\"\\nColumnas: \" + header)\n",
    "print(\"\\nPrimeras 10 filas:\")\n",
    "for i in range(10):\n",
    "    print(\"Fila {0}: {1}\".format(i,results[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traer los resultados a un DataFrame de Pandas\n",
    "Trae un query a una dataFrame de pandas.  También recibe parámetros en caso de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from hp_debito_base limit 100\"\n",
    "\n",
    "df = hp.getDataFrame(query)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultar el tamaño de una tambla (Almacenamiento físico)\n",
    "\n",
    "Devuelve el tamaño (almacenamiento físico) de una tabla de impala.  Internamente lee todos los archivos de la tabla y extrae el tamaño individual de cada uno y los suma.  Por defecto el formato esta en **Bytes**.  Se puede establecer los siguientes formatos de tamaño: \"YB\",\"ZB\",\"EB\",\"PB\",\"TB\",\"GB\",\"MB\",\"KB\", \"B\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tabla = \"resultados_vspc_clientes.master_customer_data\"\n",
    "formatos = [\"MB\" , \"GB\" , \"TB\"]\n",
    "\n",
    "sizes = [] \n",
    "for fmt in formatos:\n",
    "    tamanho = hp.tableSize( tabla , fmt )    \n",
    "    sizes.append( ( fmt , round(tamanho , 2) ) )\n",
    "    \n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar una muestra aleatoria de una tabla\n",
    "Genera una muestra aleatoria de una tabla. El tamaño de la muestra por defecto es del 1% pero se puede cambiar.\n",
    "\n",
    "\n",
    "La función recibe obligatoriamente el nombre de la tabla y las columnas con las categorías/estratos, recibe un parámetro opcional que es el tamaño de la muestra medido en el porcentaje de registros.  El resultado es una tabla del mismo nombre de la original con el sufijo **\\_muestra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de una tabla base para las muestras\n",
    "\n",
    "query = \"\"\"\n",
    "create table tabla_cli stored as parquet as \n",
    "    select tipo_cli ,  ciudad_nacim ,  cal_sarlaft\n",
    "    from resultados_vspc_clientes.master_customer_data \n",
    "    where year = 2019 and month = 11 and ingestion_day = 21\n",
    "\"\"\"\n",
    "hp.execute(\"drop table if exists tabla_cli\")\n",
    "hp.execute( query )\n",
    "hp.execute( \"compute stats tabla_cli\" )\n",
    "df = hp.getDataFrame( \"select count(*) from tabla_cli \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra aleatoria del 5%\n",
    "\n",
    "hp.muestraAleatoria( \"tabla_cli\" , pct = 0.05  )\n",
    "\n",
    "df = hp.getDataFrame( \"select count(*) from tabla_cli_muestra \")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar una muestra aleatoria estratificada de una tabla\n",
    "Genera una muestra aleatoria de una tabla por estratos o categorías. El tamaño de la muestra por defecto es del 1% pero se puede cambiar.\n",
    "\n",
    "La función recibe obligatoriamente el nombre de la tabla y las columnas con las categorías/estratos, recibe un parámetro opcional que es el tamaño de la muestra medido en el porcentaje de registros.  El resultado es una tabla del mismo nombre de la original con el sufijo **\\_muestra\\_est**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra aleatoria del 3% usando estratos las columnas de tipo cliente y ciudad\n",
    "estratos = [\"tipo_cli\" ,  \"ciudad_nacim\"]\n",
    "\n",
    "# Conteo de estratos en la tabla original.\n",
    "df1 = hp.getDataFrame(\"select tipo_cli , trim(ciudad_nacim) ciudad , count(*) as cnt from tabla_cli group by tipo_cli , ciudad_nacim\")\n",
    "print(df1)\n",
    "\n",
    "hp.muestraEstratificada( \"tabla_cli\" , estratos , pct = 0.03  )\n",
    "\n",
    "# Conteo de estratos en la tabla de muestra.\n",
    "df = hp.getDataFrame( \"select tipo_cli , trim(ciudad_nacim) ciudad , count(*)  as cnt from tabla_cli_muestra_est group by tipo_cli , ciudad_nacim \")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación One Hot Encoding\n",
    "Genera columnas con One Hot Encodings a una tabla y crea una tabla nueva con las columnas generadas.  La función tiene una variable opcional que llamada drop.  En caso de ser igual a __True__ elimina las columnas Originales que están en el One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera OHE para tabla hp_debito_base y columnas de Moneda y Bin\n",
    "rela =  hp.oneHot(\"hp_debito_base\" , [ \"pais\" ] , drop = True )\n",
    "\n",
    "print(\"\\nTotal de columnas nuevas: {0}\\n\".format(len(rela)))\n",
    "\n",
    "hp.getDataFrame(\"Select * from hp_debito_base_ohe limit 10\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla Dinámica (Transposición)\n",
    "\n",
    "Genera una nueva tabla con la transposición de una o más columnas, la función recibe el nombre de la tabla , una lista de columnas a transponer y una lista de columnas de valor que deben asignarse a la columna transpuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = hp.getDataFrame(\"Select * from myCNAME  limit 100\" )\n",
    "\n",
    "hp.transpose( \"myCNAME\" , [\"tipo_cliente\"] , [\"control_terceros\"] , [\"tipo_doc\"]) \n",
    "\n",
    "df2 = hp.getDataFrame(\"Select * from myCNAME_trans  limit 100\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estabilidad Variables\n",
    "Esta funcionalidad permite hacer dos cosas:\n",
    "\n",
    "1. Un análisis de la estabilidad de variables en términos de algún(os) campo(s) de la tabla. Por ejemplo: variables en función de una fecha de análisis.\n",
    "2. Un análisis de la distribución de las variables.\n",
    "\n",
    "## Análisis de Estabilidad\n",
    "El análisis de estabilidad consiste en calcular límites de control sobre la media y el porcentaje de completitud.\n",
    "\n",
    "### Media \n",
    "La media se calcula para todas las variables a analizar, agrupada por la(s) variable(s) de agrupación. Una vez calculada se verifica: para cada variable, en cuántos periodos la variable toma valores por fuera de las siguientes cotas:\n",
    "\n",
    "\\begin{equation*}\n",
    "l = \\mu \\pm Z_\\alpha * \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\end{equation*}\n",
    "\n",
    "Donde $\\mu$ es la media de la variable en todos los periodos. $Z_\\alpha$ corresponde al nivel de confianza (que se calcula con 90%, 95% y 99%). $\\sigma$ es la desviación estándar de todos los datos. $n$ el número de valores únicos observados observados en la variable de agrupación.\n",
    "\n",
    "### Porcentaje de No Completitud\n",
    "\n",
    "En el caso del procentaje de *missing*, las cotas están dadas por:\n",
    "\n",
    "\\begin{equation*}\n",
    "l = \\bar{p} \\pm Z_\\alpha \\sqrt{\\frac{\\bar{p} ( 1 - \\bar{p}  ) }{n}}\n",
    "\\end{equation*}\n",
    "\n",
    "En donde $\\bar{p}$ es el promedio de toda la población.\n",
    "\n",
    "\n",
    "## Análisis de Distribución\n",
    "Este módulo permite consultar para cada variable: el procentaje de completitud, el mínimo, el máximo y los percentiles 1, 10, 25, 50, 75, 90 y 99.\n",
    "\n",
    "\n",
    "## Ejecución\n",
    "Para ejecutar el código se debe indicar: (1) la tabla a revisar, (2) la variable que se utilizará para hacer el análisis de estabilidad (i.e. periodo), y (3) las variables sobre las que se hará el análisis ó las variables que deben ser excluídas del análisis (i.e. llaves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = \"proceso_cap_analit_y_gob_de_inf.rb_trx_dba_6\" # Tabla sobre la que se realizará el análisis\n",
    "grp = [\"f_analisis\"] # Variable(s) para agrupar, para el análisis de estabilidad\n",
    "variables = ['num_doc' , 'tipo_doc', 'llave_nombre', 'f_analisis' ] #Variables a excluir del análisis\n",
    "\n",
    "dfRet , dfRetT, df = hp.estabVariables(tabla , grp ,  exclude = variables )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que en el ejemplo anterior se incluyó la lista de variables a excluir del análisis. Si lo que se quiere es incluir las variables a analizar el comando a utilizar es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_analizar = [\"trx_dba_cnt_cta_6vs12\", \"trx_dba_sld_cta_6vs12\", \"trx_dba_sld_sg_6vs12\", \"trx_dba_sld_max_6vs12\"]\n",
    "dfRet , dfRetT, df = hp.estabVariables(tabla , grp ,  variables_analizar )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "El helper retorna tres dataframes: `dfRet`, `dfRetT`, y `df`.\n",
    "\n",
    "### `dfRet`\n",
    "Este dataframe tiene la información agregada por los valores únicos que toma `grp`. Específicamente, para cada valor indica cuántas variables se salen del intervalo de confianza calculado por los límites de control. El siguiente código de python le puede ayudar a tener una vista resumida de los resultados de este dataframe:\n",
    "\n",
    "```python\n",
    "dfRet['tabla'] = dfRet['tabla'].str.replace( tabla + '_', '')\n",
    "dfRet['periodo'] = dfRet['periodo'].str.replace('f_analisis: ', '')\n",
    "\n",
    "df2 = dfRet['tabla'].apply(lambda x: pd.Series(x.split('_')))\n",
    "df2.columns = ['analisis','intervalo','tipo']\n",
    "dff_p = pd.concat([df2,dfRet], axis=1)\n",
    "dff_p['n_variables'] = dff_p['variables'].str.count(',') + 1\n",
    "```\n",
    "\n",
    "El código anterior genera una tabla de 6 columnas:\n",
    "\n",
    "1. Análisis: permite identificar si es de completitud o de medias (lcm).\n",
    "2. Intervalo: puede tomar los valores de 90, 95 y 99.\n",
    "3. Tipo: se usa para discriminar si el análisis es por media o por mediana. Ignorar el de mediana ya que tiene un error en el cálculo.\n",
    "4. Periodo: valores que toman las variables de agrupación.\n",
    "5. n_variables: número de variables que se salen del intervalo.\n",
    "6. Variables: variables específicas que se salen del intervalo.\n",
    "\n",
    "\n",
    "### `dfRetT`\n",
    "Este dataframe puede entenderse como `dfRet` transpuesto. Lo que informa es para cada variable en cuantos valores únicos de `grp`, las medidas calculadas se salen del límite de control. El siguiente código de python le puede ayudar a resumir:\n",
    "\n",
    "```python\n",
    "deRetT['tabla'] = deRetT['tabla'].str.replace( tabla + '_', '')\n",
    "\n",
    "df2 = deRetT['tabla'].apply(lambda x: pd.Series(x.split('_')))\n",
    "df2.columns = ['analisis','intervalo','tipo']\n",
    "dff_v = pd.concat([df2,deRetT], axis=1)\n",
    "dff_v['n_periodos'] = dff_v['periodos'].str.count('--') + 1\n",
    "```\n",
    "El código anterior genera una tabla de 6 columnas:\n",
    "\n",
    "1. Análisis: permite identificar si es de completitud o de medias (lcm).\n",
    "2. Intervalo: puede tomar los valores de 90, 95 y 99.\n",
    "3. Tipo: se usa para discriminar si el análisis es por media o por mediana. Ignorar el de mediana ya que tiene un error en el cálculo.\n",
    "4. Periodo: valores que toman las variables de agrupación.\n",
    "5. n_variables: número de variables que se salen del intervalo.\n",
    "6. Variables: variables específicas que se salen del intervalo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### `df`\n",
    "Este dataframe muestra, para cada variable: el procentaje de completitud, el mínimo, el máximo y los percentiles 1, 10, 25, 50, 75, 90 y 99. Estos cálculos se hacen sin discriminar por las variables de agrupación `grp`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
